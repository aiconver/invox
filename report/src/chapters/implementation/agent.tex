\section{Agent Implementation}
\label{sec:impl-agents}

This section details the concrete implementation of each agent in the Invox system, covering their API contracts, processing logic, and integration patterns. Each agent exposes well-defined TypeScript interfaces and follows consistent error handling patterns. The implementation is designed to be domain-agnostic, supporting arbitrary template schemas across healthcare, manufacturing, administrative, and other domains.

\subsection{Speech-to-Text (STT) Agent}
\label{subsec:impl-stt}

The STT agent provides a single entry point \texttt{transcribeForm} that converts audio inputs to structured transcripts using OpenAI's Whisper model.

\textbf{API Contract:}
\begin{verbatim}
interface TranscribeInput {
  file: {
    base64: string;         // Base64-encoded audio data
    mimetype: string;       // "audio/wav" | "audio/mpeg" | "audio/m4a"
    originalname: string;
  };
}

interface TranscribeResponse {
  transcript: string;           // Full transcribed text
  language: string;             // Detected language code (ISO 639-1)
  durationInSeconds: number;    // Audio duration
  segments?: Array<{            // Optional word-level timing
    start: number;
    end: number;
    text: string;
    confidence?: number;
  }>;
}
\end{verbatim}

\textbf{Implementation:} The agent decodes Base64 audio data into buffers and invokes the Whisper API via the Vercel AI SDK. Long audio files (>25MB or >10 minutes) are automatically chunked with 10\% overlap to ensure context preservation at boundaries. The agent returns word-level timestamps and confidence scores when available, enabling downstream agents to trace extracted values back to specific audio segments. Failed transcriptions (e.g., due to excessive noise or unsupported formats) throw structured errors that the orchestrator can handle gracefully, either by requesting re-recording or falling back to manual text entry.

\textbf{Configuration:} Temperature is set to 0 for deterministic output. Language detection is automatic unless overridden by the client. Voice activity detection (VAD) filters out silence and non-speech segments to improve accuracy.
\subsection{Retrieval-Augmented Generation (RAG) Agent}
\label{subsec:impl-rag}

The RAG agent implements semantic search over historical templates through the \texttt{getFewShotsFromTranscript} function, which retrieves contextually relevant examples to guide the information extraction process.

\textbf{API Contract:}
\begin{verbatim}
interface RAGInput {
  transcript: string;           // Input text for similarity search
  fields: FormTemplateField[];  // Target schema for field mapping
  k?: number;                   // Number of examples (default: 5, max: 5)
}

interface FewShot {
  text: string;                 // Truncated historical transcript
  expected: Record<string, {    // Field ID → normalized value
    value: unknown | null;
    evidence?: { transcriptSnippet?: string };
  }>;
}
\end{verbatim}

\textbf{Implementation:} The agent generates dense vector embeddings using OpenAI's \texttt{text-embedding-3-large} model. A key implementation detail is the embedding generation process: the input text is prefixed with \texttt{templateId=\${TEMPLATE\_ID}} to create template-aware embeddings that improve retrieval relevance within specific template contexts.

The agent performs k-nearest neighbor search using cosine similarity in OpenSearch with the \texttt{knn\_score} script. The search query filters results by template ID to ensure schema compatibility and uses a \texttt{script\_score} approach for efficient vector similarity computation.


\textbf{Result Processing:} Retrieved documents undergo post-processing where transcript texts are truncated to a maximum character limit (default: 1200 characters) to maintain prompt efficiency. The \texttt{toExpectedShape} function maps raw database results to the expected field schema, ensuring that only fields present in the current template schema are included in the output.

\textbf{Error Handling:} The implementation includes robust error handling for embedding generation failures and OpenSearch connectivity issues. If retrieval fails, the system gracefully falls back to zero-shot extraction, ensuring continuous operation despite temporary infrastructure problems.


\subsection{Information Extraction (IE) Agent}
\label{subsec:impl-ie}

The IE agent implements four extraction strategies through unified functions corresponding to S1–S4. All strategies share a common preprocessing pipeline and differ only in their orchestration of LLM calls.

\textbf{API Contract:}
\begin{verbatim}
interface IEInput {
  oldTranscript?: string;       // Previous context (for incremental updates)
  newTranscript: string;        // New user input (primary extraction source)
  fields: FormTemplateField[];  // Schema definition
  currentValues?: Record<string, CurrentFieldValue>;
  strategy: "S1" | "S2" | "S3" | "S4";
  fewShots?: RAGOutput['examples'];  // Retrieved examples from RAG
  locale?: string;              // e.g., "en-US", "de-DE"
  timezone?: string;            // e.g., "Europe/Berlin", "America/New_York"
  templateId?: string;          // For logging and monitoring
}

interface CurrentFieldValue {
  value: any;
  locked?: boolean;             // If true, field is never overwritten
  source?: "ai" | "manual";     // Origin of current value
}

interface IEOutput {
  filled: Record<string, FilledField>;
  model: string;                // Model identifier(s) used
  confidence?: Record<string, number>;  // Per-field confidence [0,1]
}

interface FilledField {
  value: any;
  changed: boolean;             // Whether value differs from current
  previousValue?: any;          // Only present if changed=true
  source: "ai" | "manual";
  confidence?: number;          // Optional: model's certainty estimate
}
\end{verbatim}

\textbf{Strategy Implementations:}

\paragraph{S1: Single-Pass Full-Input (\texttt{singleLlmAllField})}
Constructs a comprehensive prompt requesting all template fields simultaneously. The prompt includes task instructions emphasizing extraction from \texttt{newTranscript} only, few-shot examples from RAG (up to 3 examples showing input→output mappings), field definitions with type constraints, options for enums, and guidelines, current field values with lock status, and both old and new transcript (old for context, new for extraction).

The agent uses Zod schema validation to ensure type-safe outputs. Dates must match \texttt{YYYY-MM-DD} format, numbers must be finite, and enum values must belong to the predefined set. The LLM is instructed to return a JSON object with one key per field ID. Post-processing normalizes values (e.g., joining arrays to comma-separated strings for multi-value fields, trimming whitespace) and applies lock-aware merging: if a field is locked or if the new transcript does not mention a field, the current value is preserved.

\paragraph{S2: Iterative Single-Field (\texttt{singleLlmOneField})}
Processes each field independently with a field-specific prompt. For each field: filter RAG examples to include only those that populated this specific field, construct a focused prompt with field-specific guidelines, type constraints, and 1–2 relevant examples, call the LLM with schema \texttt{\{value, confidence\}}, normalize the returned value according to field type, and apply lock-aware update logic.

Fields are processed in parallel using \texttt{Promise.all}, reducing wall-clock latency on multi-core systems. Each field call is wrapped in a try-catch block with individual error boundaries: if one field extraction fails (e.g., due to API timeout), others proceed normally and the failed field retains its current value. This isolation improves robustness compared to S1, where a single parsing error can invalidate the entire output.

\paragraph{S3: Multi-LLM Consensus Full-Input (\texttt{dualLlmAllField})}
Runs two models in parallel—GPT-4 and Gemini 2.0 Flash by default—each generating a complete template using the same prompt as S1. The outputs are then passed to a verification agent that implements consensus logic with rule-based checks to validate that locked fields were not overwritten, enum values are in the allowed set, and dates are parseable. LLM-based reconciliation uses a judge model (GPT-4o-mini by default) that compares the two candidate outputs field-by-field and selects one of four decisions per field: \texttt{gpt} (use GPT's value), \texttt{gemini} (use Gemini's value), \texttt{merge} (combine both values for multi-value text fields), or \texttt{keep\_current} (neither candidate is reliable; preserve existing value).

The verifier prompt includes both candidate outputs, the transcript, and field-level metadata (type, required status, current value). It is instructed to prefer the candidate with higher confidence, better grounding in the transcript, and consistency with schema constraints. For multi-value fields, the merge operation deduplicates and quality-filters entries, discarding empty strings or placeholders.

\paragraph{S4: Multi-LLM Consensus Per-Field (\texttt{multiLlmOneField})}
Combines the granularity of S2 with the robustness of S3. For each field: run GPT and Gemini in parallel with field-specific prompts (as in S2), pass both candidate values to a per-field verifier, apply the same decision logic as S3 but focusing on a single field to reduce prompt size and improve decision quality, and return the final value with aggregated confidence (max of the two candidates if merged).

This strategy has the highest computational cost—\textit{(number of fields)} × \textit{(number of models)} LLM calls—but provides maximum reliability by isolating errors at the field level and leveraging ensemble diversity for each slot.

\textbf{Shared preprocessing:} All strategies share common logic for incremental updates (only \texttt{newTranscript} is treated as the source of new information), lock enforcement (fields marked \texttt{locked=true} are never overwritten), change detection (the \texttt{changed} flag is set only if the final value differs from \texttt{currentValue}), and type-specific normalization to ensure consistency across strategies.

\subsection{Consistency Formatting (CF) Agent}
\label{subsec:impl-cf}

The CF agent provides \texttt{normalizeValueForField} for deterministic value standardization.

\textbf{Transformation Rules:}
\begin{verbatim}
// Date normalization: "March 3, 1992" → "1992-03-03"
function normalizeDate(value: string): string | null;

// Number parsing: "25 people" → 25 (extract leading digits)
function normalizeNumber(value: string): number | null;

// Enum validation: ensure value \in allowed options (case-insensitive)
function validateEnum(value: string, options: string[]): string | null;

// Multi-value handling: ["A", "B", null, ""] → "A, B"
function joinMultiValue(values: any[]): string | null;

// Text trimming: remove leading/trailing whitespace and normalize Unicode
function normalizeText(value: string): string | null;
\end{verbatim}

\textbf{Implementation:} The agent applies type-specific normalization rules using standard libraries: Luxon for date parsing, regex patterns for number extraction, and case-insensitive matching for enums. For text and textarea fields, Unicode normalization (NFC form) ensures consistent representation of accented characters across different input methods. Multi-value fields (identified by \texttt{type="textarea"} in schema) join array inputs into comma-separated strings, filtering out null, empty, or placeholder values.

Ambiguous values that cannot be normalized deterministically (e.g., "\texttt{3/4/92}" with unclear month/day order) are flagged with an issue annotation for the verification agent to resolve. The CF agent is intentionally non-stochastic: given the same input, it always produces the same output, ensuring reproducibility across runs.

\subsection{Verification Agent (VER)}
\label{subsec:impl-ver}

The verification agent implements \texttt{runVerifier} for single-model outputs and \texttt{runEnsembleVerifier} for multi-model consensus (S3/S4).

\textbf{API Contract:}
\begin{verbatim}
interface VerificationInput {
  candidates: Record<string, FilledField> | Record<string, FilledField>[];
  transcript: string;           // Combined old + new for context
  fields: FormTemplateField[];
  currentValues?: Record<string, CurrentFieldValue>;
}

interface VerificationOutput {
  filled: Record<string, FilledField>;
  confidence: Record<string, number>;   // Calibrated per-field confidence
  issues?: Array<{
    field: string;
    type: "missing" | "conflict" | "low_conf" | "invalid";
    detail: string;
    action?: "requery" | "clarify" | "manual_review";
  }>;
  decisions?: Array<{             // Only for ensemble strategies
    field: string;
    decision: "gpt" | "gemini" | "merge" | "keep_current";
    reason: string;
  }>;
}
\end{verbatim}

\textbf{Consensus Logic (for S3/S4):} The agent uses a judge LLM to evaluate candidate extractions field-by-field. The judge prompt includes candidate values from all models, current field values with lock status, transcript snippets for evidence grounding, schema constraints (type, required, options), and decision rules emphasizing transcript consistency, confidence scores, and lock respect.

The judge must return a structured decision per field. For multi-value fields, the \texttt{merge} decision triggers intelligent deduplication: values are normalized, duplicates removed, and the combined list returned. Confidence scores are aggregated using max (if merged) or inherited from the selected model.

\textbf{Single-Model Verification (for S1/S2):} When only one candidate is available, VER performs completeness checks to identify required fields that remain null or empty, type validation to ensure dates are parseable and numbers are finite, cross-field consistency to detect logical contradictions, and optional grounding checks to verify that extracted values are entailed by the transcript.

Issues are prioritized: low-confidence extractions suggest \texttt{"manual\_review"}, and contradictions require \texttt{"clarify"} with user input.


\subsection{Agent Orchestration}
\label{subsec:impl-orchestration}

The \texttt{Orchestrator} class coordinates agent execution through typed procedure calls exposed via tRPC endpoints. The orchestrator is strategy-aware: it selects the appropriate IE function (S1–S4) based on client configuration and manages the pipeline flow.

\textbf{Core orchestration logic:}
\begin{verbatim}
class Orchestrator {
  async processTemplate(input: ProcessingRequest): Promise<FinalTemplate> {
    // Step 1: Transcription (optional)
    const transcript = input.audio 
      ? await stt.transcribe(input.audio)
      : { transcript: input.text, language: input.lang ?? "en" };

    // Step 2: Retrieval (RAG)
    const examples = await rag.retrieve(
      transcript.transcript,
      input.fields,
      input.templateId
    );

    // Step 3: Extraction (strategy-dependent)
    const extraction = await this.runStrategy({
      strategy: input.strategy,
      transcript: transcript.transcript,
      fields: input.fields,
      currentValues: input.currentValues,
      fewShots: examples.examples,
      ...input.metadata,
    });

    // Step 4: Formatting (deterministic normalization)
    const normalized = await cf.normalize(extraction.filled, input.fields);

    // Step 5: Verification (completeness + consistency)
    const verified = await ver.verify({
      candidates: normalized,
      transcript: transcript.transcript,
      fields: input.fields,
      currentValues: input.currentValues,
    });

    // Step 6: Clarification loop (if needed)
    if (verified.issues?.some(i => i.action === "requery")) {
      // Re-run IE with hints from VER, then re-verify
    }

    return {
      filled: verified.filled,
      confidence: verified.confidence,
      issues: verified.issues,
      model: extraction.model,
      transcript: transcript.transcript,
    };
  }

  private async runStrategy(params: StrategyParams): Promise<IEOutput> {
    switch (params.strategy) {
      case "S1": return await singleLlmAllField(params);
      case "S2": return await singleLlmOneField(params);
      case "S3": return await dualLlmAllField(params);
      case "S4": return await multiLlmOneField(params);
    }
  }
}
\end{verbatim}
