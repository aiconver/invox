\section{Strategy Implementation}
\label{sec:impl-strategies}

This section details the technical realization of the four architectural strategies introduced in Section~\ref{sec:architectural-strategies}. While the conceptual trade-offs were established previously, this section focuses on the concrete implementation patterns, code organization, and execution flows that differentiate each strategy in practice.

\subsection{S1 Implementation: Single-Pass Full-Input}
\label{subsec:impl-s1}

The S1 strategy is implemented through the \texttt{singleLlmAllField} function, which orchestrates a linear pipeline with minimal branching.

\textbf{Execution Flow:}
\begin{verbatim}
// Core S1 implementation
export async function singleLlmAllField(
  input: GetFilledTemplateInput
): Promise<GetFilledTemplateResult> {
  // 1. Combine transcripts
  const combinedTranscript = oldText ? `${oldText}\n${newText}` : newText;
  
  // 2. Retrieve few-shot examples
  const fewShots = await getFewShotsFromTranscript(combinedTranscript, fields, 3);
  
  // 3. Single LLM call for all fields
  const schema = z.object(/* comprehensive field schema */);
  const result = await generateObject({
    model: openai(modelName),
    schema,
    prompt: buildComprehensivePrompt(fields, oldText, newText, fewShots),
  });
  
  // 4. Process results
  const filled = processAllFields(result.object, fields, currentValues);
  const verified = await runVerifier(combinedTranscript, fields, filled);
  
  return { filled: verified, model: modelName, transcript: transcriptData };
}
\end{verbatim}

\textbf{Key Implementation Characteristics:}
\begin{itemize}
    \item \textbf{Single Schema Definition:} One Zod schema encompassing all template fields
    \item \textbf{Unified Prompt Construction:} Single prompt containing all field definitions and examples
    \item \textbf{Batch Processing:} All fields processed simultaneously in normalization and verification
    \item \textbf{Minimal Orchestration:} Straightforward sequential execution without parallelization logic
\end{itemize}

\subsection{S2 Implementation: Iterative Single-Field}
\label{subsec:impl-s2}

The S2 strategy is implemented through \texttt{singleLlmOneField}, which introduces field-level parallelism and individual error handling.

\textbf{Execution Flow:}
\begin{verbatim}
export async function singleLlmOneField(
  input: GetFilledTemplateInput
): Promise<GetFilledTemplateResult> {
  const fewShots = await getFewShotsFromTranscript(combinedTranscript, fields, 3);
  
  // Parallel field processing with individual error boundaries
  const tasks = fields.map(field => 
    runField({
      field,
      oldText, newText,
      fewShots,
      current: currentValues?.[field.id],
      modelName,
    }).catch(error => {
      // Field-level error recovery
      return [field.id, getFallbackField(field, currentValues)];
    })
  );
  
  const entries = await Promise.all(tasks);
  return {
    filled: Object.fromEntries(entries),
    model: modelName,
    transcript: transcriptData,
  };
}
\end{verbatim}

\textbf{Key Implementation Characteristics:}
\begin{itemize}
    \item \textbf{Field-Specific Prompts:} Individual prompts per field with filtered few-shot examples
    \item \textbf{Parallel Execution:} \texttt{Promise.all} for concurrent field processing
    \item \textbf{Individual Error Boundaries:} Try-catch blocks around each field extraction
    \item \textbf{Selective RAG Filtering:} Field-specific example selection from retrieved few-shots
\end{itemize}

\subsection{S3 Implementation: Multi-LLM Consensus}
\label{subsec:impl-s3}

The S3 strategy is implemented through \texttt{dualLlmAllField}, introducing model-level parallelism and consensus verification.

\textbf{Execution Flow:}
\begin{verbatim}
export async function dualLlmAllField(
  input: GetFilledTemplateInput
): Promise<GetFilledTemplateResult> {
  // Parallel model execution
  const [gptResult, geminiResult] = await Promise.all([
    generateObject({ model: openai(gptModel), schema, prompt }),
    generateObject({ model: google(geminiModel), schema, prompt })
  ]);
  
  // Consensus verification
  const verified = await runEnsembleVerifier({
    combinedTranscript,
    fields,
    currentValues,
    gpt: buildCandidate(gptResult.object, fields, currentValues),
    gemini: buildCandidate(geminiResult.object, fields, currentValues),
  });
  
  return {
    filled: verified.filled,
    model: `ensemble:${gptModel}+${geminiModel}`,
    transcript: transcriptData,
  };
}
\end{verbatim}

\textbf{Key Implementation Characteristics:}
\begin{itemize}
    \item \textbf{Model Parallelism:} Concurrent execution of multiple LLM providers
    \item \textbf{Consensus Engine:} Specialized verifier with judge LLM for candidate selection
    \item \textbf{Decision Tracking:} Structured logging of model choices and rationales
    \item \textbf{Provider Abstraction:} Unified interface for different model providers
\end{itemize}

\subsection{S4 Implementation: Multi-LLM Per-Field}
\label{subsec:impl-s4}

The S4 strategy is implemented through \texttt{multiLlmOneField}, combining field-level and model-level parallelism with granular consensus.

\textbf{Execution Flow:}
\begin{verbatim}
export async function multiLlmOneField(
  input: GetFilledTemplateInput
): Promise<GetFilledTemplateResult> {
  const results: [string, FilledField][] = [];
  
  // Sequential field processing (rate limit avoidance)
  for (const field of fields) {
    const entry = await runOneFieldWithEnsemble({
      field,
      oldText, newText,
      fewShots,
      current: currentValues?.[field.id],
      gptModel, geminiModel, verifierModel,
    });
    results.push(entry);
  }
  
  return {
    filled: Object.fromEntries(results),
    model: `ensemble-per-field:${gptModel}+${geminiModel}`,
    transcript: transcriptData,
  };
}
\end{verbatim}

\textbf{Key Implementation Characteristics:}
\begin{itemize}
    \item \textbf{Sequential Field Processing:} Rate-limited execution to avoid API throttling
    \item \textbf{Per-Field Ensemble:} Multiple models per individual field
    \item \textbf{Granular Verification:} Field-specific judge prompts for precise decision making
    \item \textbf{Complex Error Handling:} Multi-level recovery for both field and model failures
\end{itemize}

\subsection{Strategy Orchestration Infrastructure}
\label{subsec:impl-orchestration}

The strategy selection and execution is managed through a unified orchestrator that provides consistent interfaces across all approaches.

\textbf{Orchestrator Interface:}
\begin{verbatim}
class StrategyOrchestrator {
  async executeStrategy(
    input: ProcessingRequest
  ): Promise<FinalTemplate> {
    const strategyImpl = this.getStrategyImplementation(input.strategy);
    return await strategyImpl.execute(input);
  }
  
  private getStrategyImplementation(strategy: Strategy): StrategyImplementation {
    switch (strategy) {
      case "S1": return new SinglePassStrategy();
      case "S2": return new IterativeStrategy(); 
      case "S3": return new MultiModelFullStrategy();
      case "S4": return new MultiModelSlotStrategy();
    }
  }
}
\end{verbatim}

\textbf{Common Infrastructure:}
\begin{itemize}
    \item \textbf{Unified Error Handling:} Consistent error types and recovery patterns across strategies
    \item \textbf{Telemetry Integration:} Standardized logging of performance metrics and decision points
    \item \textbf{Configuration Management:} Environment-based strategy configuration and model selection
    \item \textbf{Result Serialization:} Consistent output formatting regardless of strategy complexity
\end{itemize}

The implementation maintains architectural consistency while allowing each strategy to optimize for different operational constraints, providing a flexible foundation for empirical evaluation across diverse deployment scenarios.