During a night shift at a manufacturing plant, an operator notices unusual vibrations in a critical machine and must document equipment performance and anomalies for the incoming team. In a busy emergency room, a doctor treating a patient with chest pain must record symptoms, vitals, medical history, and treatments in a standardized intake form. Although from different domains, both tasks rely on structured information capture to ensure continuity, safety, and compliance.

Across industries—including healthcare, manufacturing, logistics, and customer service—workers routinely populate templates such as forms, logs, and reports. This general task, known as \textit{template filling}, requires mapping unstructured observations into predefined fields. It is essential for documentation quality but also time-consuming and error-prone, especially when workers are fatigued. Manual entries often vary in detail, omit required fields, or contain stylistic inconsistencies that impede downstream analysis.

Template filling appears in many settings, from clinical intake forms~\cite{du2021template} and industrial maintenance logs~\cite{wang2021spoken} to web automation~\cite{chen2024webform} and customer service platforms~\cite{sun2023slot}. The main challenge is not collecting information but reliably converting unstructured text—or speech—into structured formats. This cognitive effort can be significant, especially after demanding shifts where important details may be forgotten or recorded inconsistently.

AI assistants and modern NLP technologies offer an alternative: users can describe events freely, and AI systems convert these descriptions into structured template fields. This reduces cognitive load, improves consistency, and allows the system to detect missing or contradictory information. In hands-busy environments—such as technicians wearing protective gear or clinicians examining patients—speech-based filling is especially promising~\cite{wang2021spoken}.

This shift is driven by advances in \textit{automatic speech recognition (ASR)} and \textit{large language models (LLMs)}. ASR systems like Whisper now transcribe speech accurately across accents, noise levels, and informal phrasing~\cite{radford2023whisper, fathullah2023prompting}. Meanwhile, LLMs such as GPT-4 and Claude can interpret context, extract structured information, and resolve ambiguities in user descriptions~\cite{du2021template, mialon2023augmented}.

Most current ASR+LLM systems rely on a \textit{monolithic} design in which a single model performs understanding and template filling~\cite{sun2022023slot, chen2024webform}. Such systems offer simplicity but lack transparency and are difficult to adapt: errors cannot be traced to specific steps, and new forms often require retraining the entire model~\cite{liu2022conversational}. Spoken input further complicates the pipeline—speech is frequently disfluent, unordered, or incomplete~\cite{fathullah2023prompting}.

To overcome these limitations, recent work advocates \textit{modular or multi-agent architectures}, where transcription, field identification, value extraction, and validation are handled by separate components~\cite{mialon2023augmented, schick2023toolformer}. This improves interpretability, maintainability, and adaptability to new domains. Building on this line of research, this thesis presents \textbf{Invox}, a modular system for speech-based template filling tailored to realistic industrial conditions.

\section{Problem Description}

Large language models (LLMs) have made automatic form filling more accessible, but most existing systems use a \textit{monolithic design} in which a single model reads the input and generates all fields at once. Examples include zero-shot template generation~\cite{du2021template}, single-pass webform completion~\cite{chen2024webform}, and unified slot-filling pipelines~\cite{sun2023slot}. These approaches work in controlled settings but break down with real-world input, which is often unstructured, incomplete, ambiguous, or contains irrelevant details. Whether the input is text, dialogue, or speech, the core challenge remains: converting loosely structured human communication into rigid template fields.

A major limitation is \textit{fragility}. Monolithic models struggle when users speak naturally, reorder information, use unusual phrasing, or omit details~\cite{fathullah2023prompting, liu2022conversational}. They may leave fields empty, fill them incorrectly, or produce inconsistent outputs~\cite{wang2021spoken, sun2023slot}.

Another issue is \textit{lack of transparency}. When one model performs every step, it becomes impossible to tell whether an error stems from transcription, understanding, or incorrect field assignment~\cite{schick2023toolformer}. This makes failures hard to diagnose.

\textit{Adaptation} is also difficult. Different industries and forms require different field structures and vocabularies, and updating a monolithic system often requires retraining or redesigning the entire pipeline~\cite{du2021template, mialon2023augmented}.

These problems persist because current research typically evaluates isolated components rather than full systems. Although specific models excel at tasks like extraction or validation, there is no flexible, end-to-end architecture that integrates them reliably. As a result, one-shot systems fail when templates change, input quality varies, or new fields must be added.

To overcome these limitations, a modular and transparent design is needed—one that breaks the task into interpretable steps, improving error detection, debugging, and adaptation across domains~\cite{mialon2023augmented, schick2023toolformer}.

\section{Motivating Scenario}

To illustrate the challenges of template filling in real-world environments, consider a typical shift in the \textit{steel manufacturing industry}.

Steel plant operators work under intense conditions—loud machinery, high heat, and strict production deadlines. At the end of each 8-hour shift, they are expected to submit a \textit{shift report} documenting safety incidents, equipment issues, production figures, and handover notes. These reports are essential for maintaining operational continuity, safety compliance, and accountability. Yet in practice, workers often fill them out hastily—sometimes incompletely or not at all—especially during late-night shifts or when fatigued.

To reduce the burden of manual form filling, workers and organizations have begun exploring various assistive technologies and workarounds. While many organizations have transitioned to digitalized forms accessible via tablets or computers, the fundamental challenge of structuring information remains unchanged—workers still must manually map their observations into predefined fields. Some organizations have experimented with dictation tools or voice recording as intermediate steps, where workers provide free-form descriptions that supervisors later process into structured reports. However, such approaches merely shift the burden rather than solving it: someone must still perform the cognitive work of listening to unstructured accounts and extracting relevant information for each template field. This highlights a critical need for intelligent systems that can assist in the transformation from unstructured human communication to structured data, regardless of the input modality.

Now imagine an intelligent system that could take these raw audio notes, transcribe them, interpret their meaning, and fill in the shift report automatically. For instance, if a worker says:

\begin{quote}
``We had a minor safety incident near the blast furnace around 2 p.m.—someone tripped, but no injuries. Conveyor belt on Line B stopped twice, restarted after 10 minutes each time. Production target met—482 tons.''
\end{quote}

Such a system would ideally extract structured information like:
\begin{itemize}
    \item \textbf{Safety Incident:} Minor, near blast furnace, no injuries
    \item \textbf{Time:} Around 2 p.m.
    \item \textbf{Equipment Issue:} Line B conveyor belt stopped twice
    \item \textbf{Production:} 482 tons
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.28]{images/Motivation.png}
    \caption{Invox: From spoken input to structured report}
    \label{fig:invox-motivation}
\end{figure}

Although this task may seem straightforward, it is far from trivial. Spoken input is often informal, unordered, and filled with vague expressions or filler words. Terms like “blast furnace” or “Line B” reflect domain-specific knowledge that the system must understand. Noise, fatigue, and rushed speech introduce further variability.

This scenario reveals four core challenges in automating template filling:
\begin{itemize}
\item \textbf{Unstructured input:} Workers communicate naturally through free-form descriptions rather than following predefined template structures, requiring systems to interpret and map loosely organized information into rigid formats.
\item \textbf{Inconsistency and incompleteness:} Human-generated descriptions vary widely in detail, writing style, and vocabulary, often omitting critical information or including irrelevant details that must be filtered out.
\item \textbf{Domain-specific language:} Specialized terminology, abbreviations, and jargon must be correctly recognized and interpreted within their contextual meaning, which varies across industries and departments.
\item \textbf{Lack of integrated systems:} Current solutions rely on isolated AI models rather than flexible, end-to-end systems that can adapt to different template formats, handle multiple input modalities, and evolve with changing organizational needs.
\end{itemize}

Together, these challenges underscore the need for a more intelligent and adaptable approach. A modular system like \textbf{Invox}, capable of processing speech, identifying relevant fields, and generating structured output, offers a scalable solution tailored to the complexities of real industrial environments.


\section{Scope of the Thesis}
This thesis focuses on practical form-filling methods that convert noisy, unstructured spoken input into structured digital records, introducing realistic benchmark datasets and, to the best of our knowledge, the first end-to-end system based on large-scale pretrained models that can be efficiently used in real-world applications.

The primary use case addressed is shift documentation in the steel manufacturing industry. Operators in this domain often record verbal summaries at the end of their shifts, describing production events, safety incidents, and equipment issues. These recordings are typically informal, multilingual, and captured in noisy environments. This makes the use case ideal for evaluating robustness in low-structure, real-world input scenarios~\cite{wang2021spoken, fathullah2023prompting}.

The technical scope of this work includes the use of state-of-the-art automatic speech recognition (ASR) models—specifically OpenAI's Whisper~\cite{radford2023whisper}—combined with large language models (LLMs) such as GPT-5, Gemini-2.5-pro, etc. These components are orchestrated in a modular agent-based architecture for handling tasks like transcription interpretation, field-value mapping, and validation. No fine-tuning or training of models is performed; the focus is on system-level orchestration and domain-adapted prompt engineering.

The evaluation is limited to the accuracy and reliability of the structured output produced from recorded input. This thesis does not cover areas such as UI/UX design, live streaming input, conversational turn-taking, or the deployment of on-device inference. Instead, it aims to explore how existing ASR and LLM technologies can be effectively combined into a practical and scalable speech-based form filling system suitable for high-noise industrial domains.


\section{Objectives}

The main objective of this thesis is to design and evaluate a modular system—called \textbf{Invox}—that can automatically fill out structured forms using unstructured speech or text input. The system aims to overcome the limitations of current single-model, end-to-end solutions by introducing a flexible, multi-agent approach that separates the task into smaller, specialized components.

To achieve this goal, the following two specific objectives are defined:

\begin{enumerate}
    \item \textbf{Design a modular multi-agent architecture} for template filling that separates the process into subtasks such as transcription, field detection, answer generation, and verification—each handled by a dedicated agent. This design supports flexibility, transparency, and domain adaptability. As part of this design, five distinct prompting strategies are implemented using large language models (LLMs), ranging from single-pass full-input methods to iterative multi-model consensus approaches. These strategies are chosen to reflect different trade-offs in accuracy, latency, cost, and interpretability.

    \item \textbf{Evaluate the system performance} using a hybrid strategy that combines standardized benchmarking and real-world testing. For benchmarking, the official MUC-4 evaluation protocol \cite{chinchor1992muc4} is applied, using slot-level precision, recall, and F1-score to compare structured information extraction. Finally, results from all prompting strategies are compared to identify the most effective architectural approach under various real-world conditions.
\end{enumerate}

These objectives guide the development and validation of a system that is not only technically sound but also practical and scalable in industrial settings.

\section{Thesis Outline}

Following this introduction, the thesis begins with a review of related work on template filling, speech-based systems, and large language models. The literature is analyzed to identify current limitations and to derive requirements for a more modular and reliable solution. This provides the conceptual foundation for understanding the need for a system like Invox.

The next chapter introduces the overall system concept. It presents the structure of Invox together with four design strategies that employ LLMs in different ways. After outlining the concept, the implementation chapter describes the software architecture, technology choices, and how core components—such as transcription, retrieval, extraction, and verification—were developed, with an emphasis on modularity and reuse.

The following chapters demonstrate and evaluate the system. A working prototype is shown through screenshots and examples illustrating how speech input is transformed into structured forms. The evaluation then examines system performance on a benchmark dataset across the four architectural strategies, using metrics such as accuracy, latency, consistency, and cost. The thesis concludes by summarizing key findings, discussing limitations, and outlining opportunities for future work.
