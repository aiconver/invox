
\section{Background and Situation}

During a night shift at a manufacturing plant, an operator notices unusual vibrations in a critical machine. Before leaving, they must document the equipment's performance, note any anomalies, and summarize safety incidents in a detailed shift handover report—ensuring the incoming team can respond appropriately. Similarly, in a busy emergency room, a doctor treating a patient with chest pain must carefully record vital signs, symptoms, medical history, and prescribed treatments in a standardized intake form. This documentation not only guides the next attending physician but also ensures compliance with medical protocols and legal requirements.

These scenarios, while spanning vastly different domains, share a common thread: the need for structured information capture to inform others about critical findings and document important processes. Across industries—from healthcare and manufacturing to customer service and logistics—workers routinely collect and organize information into standardized formats such as forms, logs, and reports. In its generalized form, these reports follow predefined templates with specific fields that must be accurately filled. In an even more abstract sense, the task of populating values into these predefined fields is known as \textit{template filling}.

This process is employed across various industries, including healthcare~\cite{du2021template}, manufacturing~\cite{wang2021spoken}, web-based automation~\cite{chen2024webform}, and customer service platforms~\cite{sun2023slot}. In these environments, structured data entry is crucial for ensuring operational continuity, regulatory compliance, and informed decision-making. The challenge lies not just in collecting information, but in accurately mapping unstructured observations and conversations into the rigid structure of predefined templates—a task that is both time-consuming and prone to human error.

Traditionally, template filling has been performed manually, either by writing on paper or typing into digital forms. However, this approach suffers from several fundamental challenges that compromise data quality and operational efficiency. Forms are often inconsistent in their level of detail, incomplete due to rushed or fatigued workers, and contain errors ranging from simple typos to logical contradictions between fields. Different individuals bring varying writing styles and vocabularies to the same task, making it difficult to standardize and extract insights from collected data. Moreover, the process of filling out forms is not merely clerical—it requires intellectual effort to articulate observations, recall details, and structure thoughts into predefined categories. This cognitive load becomes particularly problematic when workers must complete documentation after physically or mentally demanding shifts. A factory operator finishing a 12-hour shift or a nurse at the end of a hectic emergency room rotation may struggle to recall critical details or inadvertently skip important sections of a form. In such states of fatigue, vital information may be forgotten, nuances lost, and mandatory fields left blank, potentially compromising safety protocols, continuity of care, or operational decision-making.

Emerging technologies such as AI assistants and natural language processing have the potential to radically transform how forms are filled. Rather than requiring users to manually structure their thoughts into rigid template fields, AI systems can interpret free-form descriptions—whether typed or spoken—and automatically populate the appropriate template fields. This approach not only reduces cognitive burden and time investment but also improves consistency and completeness by intelligently prompting for missing information and detecting logical inconsistencies. In scenarios where hands-free operation is essential, such as field technicians wearing protective gear or medical professionals conducting examinations, speech-based template filling offers a particularly promising modality by allowing users to dictate their observations naturally while AI handles the structured data entry~\cite{wang2021spoken}.

This shift toward voice interaction is made possible by recent progress in artificial intelligence, particularly in \textit{automatic speech recognition (ASR)} and \textit{large language models (LLMs)}. ASR systems like OpenAI’s Whisper have achieved strong performance in transcribing speech accurately, even in noisy or informal conditions~\cite{radford2023whisper, fathullah2023prompting}. These models can handle multiple accents, technical terminology, and varying background noise, making them suitable for real-world applications such as hospitals and factories~\cite{wang2021spoken}.

Meanwhile, LLMs such as GPT-4 and Claude have transformed natural language processing by enabling machines to understand context, extract relevant information, and generate structured outputs from unstructured inputs~\cite{du2021template, schick2023toolformer}. These models are capable of filling out complex templates if given the correct input format, and can even infer missing details or resolve ambiguities in the user's statements~\cite{mialon2023augmented}.

However, current systems that combine ASR and LLMs often use a \textit{monolithic architecture}, where a single model performs the entire task of understanding and filling out the form~\cite{sun2023slot, chen2024webform}. While this approach is simple to implement, it lacks flexibility and interpretability. Errors are hard to trace back to a specific step, and adapting the system to a new form or domain usually requires retraining the entire pipeline~\cite{liu2022conversational, schick2023toolformer}. This becomes especially problematic when dealing with spoken inputs, which can be disfluent, unordered, or incomplete~\cite{fathullah2023prompting}.

As a response to these limitations, recent research suggests using \textit{modular or multi-agent architectures}, where each component of the system (e.g., transcription, field identification, value extraction) is handled separately~\cite{mialon2023augmented, schick2023toolformer}. This design enables better control, easier debugging, and smoother integration of new improvements. This thesis builds upon this idea by developing a modular system—called \textbf{Invox}—that focuses on speech-based template filling in realistic, industrial environments.


\section{Problem Description}

While recent advances in large language models (LLMs) have made it easier to build systems for filling out forms automatically, most existing solutions rely on a \textit{monolithic design}, where a single model handles the entire task of understanding input and generating all required field values in one step. For instance, Du et al.~\cite{du2021template} propose zero-shot prompting to generate complete templates from unstructured text, while Chen et al.~\cite{chen2024webform} apply large language models to populate web-based forms via single-shot prompts. Similarly, Sun et al.~\cite{sun2023slot} introduce a slot-filling pipeline that decodes all fields in a unified pass. Although effective in controlled settings, such monolithic approaches become brittle when processing real-world input, which is often unstructured, incomplete, ambiguous, or contains irrelevant information—making these systems hard to adapt, debug, or extend across domains. Whether the input comes from free-form text descriptions, conversational dialogue, or speech transcriptions, the fundamental challenge remains: mapping loosely structured human communication into rigid template formats while handling the inherent messiness of natural language.

One major issue is \textit{fragility}. These models are often trained on specific types of inputs or formats, and they may fail when the input varies slightly—such as when someone uses uncommon phrasing, mixes up the order of fields, or leaves out certain information~\cite{fathullah2023prompting, liu2022conversational}. This is common in real-world situations, where people speak naturally and often provide extra details, use abbreviations, or skip fields they assume are obvious. When a monolithic model encounters this variation, it might leave fields blank, insert wrong values, or produce inconsistent results~\cite{wang2021spoken, sun2023slot}.

Another major challenge is \textit{lack of transparency}. When a single model does the entire job, it is difficult to figure out what went wrong if the result is incorrect. For example, was the problem caused by a transcription error, misunderstanding of the content, or a failure in mapping the answer to the correct field? Because all steps are handled together, it is hard to trace and fix errors, which limits the system’s reliability and maintainability~\cite{schick2023toolformer}.

Additionally, current systems are \textit{hard to customize} for different industries or forms. Each form may have its own structure, required fields, and domain-specific language. Changing the model to handle a new type of report or form often means retraining or redesigning the entire system~\cite{du2021template, mialon2023augmented}. This makes it expensive and time-consuming to adapt these systems to new domains.

These problems are even more pronounced because current approaches present isolated AI models rather than complete, flexible systems. While individual models may excel at specific subtasks—such as information extraction, field classification, or consistency validation—there is no readily-usable end-to-end system that integrates these capabilities in a cohesive and adaptable manner. In practice, building robust template filling solutions requires combining multiple specialized models and components to create an improved process that can handle real-world variability, domain-specific requirements, and evolving template structures. As a result, current one-step systems often fail in practical deployment scenarios where templates vary across departments, input quality is inconsistent, or the system needs to adapt to new fields and formats over time without requiring complete retraining.

To solve these problems, there is a need for a more flexible, transparent, and modular approach that separates the process into smaller, understandable steps. This allows better error handling, easier debugging, and faster adaptation to new use cases~\cite{mialon2023augmented, schick2023toolformer}.

\section{Motivating Scenario}

To illustrate the challenges of template filling in real-world environments, consider a typical shift in the \textit{steel manufacturing industry}.

Steel plant operators work under intense conditions—loud machinery, high heat, and strict production deadlines. At the end of each 8-hour shift, they are expected to submit a \textit{shift report} documenting safety incidents, equipment issues, production figures, and handover notes. These reports are essential for maintaining operational continuity, safety compliance, and accountability. Yet in practice, workers often fill them out hastily—sometimes incompletely or not at all—especially during late-night shifts or when fatigued.

To reduce the burden of manual form filling, workers and organizations have begun exploring various assistive technologies and workarounds. While many organizations have transitioned to digitalized forms accessible via tablets or computers, the fundamental challenge of structuring information remains unchanged—workers still must manually map their observations into predefined fields. Some organizations have experimented with dictation tools or voice recording as intermediate steps, where workers provide free-form descriptions that supervisors later process into structured reports. However, such approaches merely shift the burden rather than solving it: someone must still perform the cognitive work of listening to unstructured accounts and extracting relevant information for each template field. This highlights a critical need for intelligent systems that can assist in the transformation from unstructured human communication to structured data, regardless of the input modality.

Now imagine an intelligent system that could take these raw audio notes, transcribe them, interpret their meaning, and fill in the shift report automatically. For instance, if a worker says:

\begin{quote}
``We had a minor safety incident near the blast furnace around 2 p.m.—someone tripped, but no injuries. Conveyor belt on Line B stopped twice, restarted after 10 minutes each time. Production target met—482 tons.''
\end{quote}

Such a system would ideally extract structured information like:
\begin{itemize}
    \item \textbf{Safety Incident:} Minor, near blast furnace, no injuries
    \item \textbf{Time:} Around 2 p.m.
    \item \textbf{Equipment Issue:} Line B conveyor belt stopped twice
    \item \textbf{Production:} 482 tons
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.35]{images/Motivation.png}
    \caption{Invox: From spoken input to structured report}
    \label{fig:invox-motivation}
\end{figure}

Although this task may seem straightforward, it is far from trivial. Spoken input is often informal, unordered, and filled with vague expressions or filler words. Terms like “blast furnace” or “Line B” reflect domain-specific knowledge that the system must understand. Noise, fatigue, and rushed speech introduce further variability.

This scenario reveals four core challenges in automating template filling:
\begin{itemize}
\item \textbf{Unstructured input:} Workers communicate naturally through free-form descriptions rather than following predefined template structures, requiring systems to interpret and map loosely organized information into rigid formats.
\item \textbf{Inconsistency and incompleteness:} Human-generated descriptions vary widely in detail, writing style, and vocabulary, often omitting critical information or including irrelevant details that must be filtered out.
\item \textbf{Domain-specific language:} Specialized terminology, abbreviations, and jargon must be correctly recognized and interpreted within their contextual meaning, which varies across industries and departments.
\item \textbf{Lack of integrated systems:} Current solutions rely on isolated AI models rather than flexible, end-to-end systems that can adapt to different template formats, handle multiple input modalities, and evolve with changing organizational needs.
\end{itemize}

Together, these challenges underscore the need for a more intelligent and adaptable approach. A modular system like \textbf{Invox}, capable of processing speech, identifying relevant fields, and generating structured output, offers a scalable solution tailored to the complexities of real industrial environments.


\section{Scope of the Thesis}
This thesis focuses on practical form-filling methods that convert noisy, unstructured spoken input into structured digital records, introducing realistic benchmark datasets and, to the best of our knowledge, the first end-to-end system based on large-scale pretrained models that can be efficiently used in real-world applications.

The primary use case addressed is shift documentation in the steel manufacturing industry. Operators in this domain often record verbal summaries at the end of their shifts, describing production events, safety incidents, and equipment issues. These recordings are typically informal, multilingual, and captured in noisy environments. This makes the use case ideal for evaluating robustness in low-structure, real-world input scenarios~\cite{wang2021spoken, fathullah2023prompting}.

The technical scope of this work includes the use of state-of-the-art automatic speech recognition (ASR) models—specifically OpenAI's Whisper~\cite{radford2023whisper}—combined with large language models (LLMs) such as GPT-5, Gemini-2.5-pro, etc. These components are orchestrated in a modular agent-based architecture for handling tasks like transcription interpretation, field-value mapping, and validation. No fine-tuning or training of models is performed; the focus is on system-level orchestration and domain-adapted prompt engineering.

The evaluation is limited to the accuracy and reliability of the structured output produced from recorded input. This thesis does not cover areas such as UI/UX design, live streaming input, conversational turn-taking, or the deployment of on-device inference. Instead, it aims to explore how existing ASR and LLM technologies can be effectively combined into a practical and scalable speech-based form filling system suitable for high-noise industrial domains.


\section{Objectives}

The main objective of this thesis is to design and evaluate a modular system—called \textbf{Invox}—that can automatically fill out structured forms using unstructured speech or text input. The system aims to overcome the limitations of current single-model, end-to-end solutions by introducing a flexible, multi-agent approach that separates the task into smaller, specialized components.

To achieve this goal, the following two specific objectives are defined:

\begin{enumerate}
    \item \textbf{Design a modular multi-agent architecture} for template filling that separates the process into subtasks such as transcription, field detection, answer generation, and verification—each handled by a dedicated agent. This design supports flexibility, transparency, and domain adaptability. As part of this design, five distinct prompting strategies are implemented using large language models (LLMs), ranging from single-pass full-input methods to iterative multi-model consensus approaches. These strategies are chosen to reflect different trade-offs in accuracy, latency, cost, and interpretability.

    \item \textbf{Evaluate the system performance} using a hybrid strategy that combines standardized benchmarking and real-world testing. For benchmarking, the official MUC-4 evaluation protocol \cite{chinchor1992muc4} is applied, using slot-level precision, recall, and F1-score to compare structured information extraction. Finally, results from all prompting strategies are compared to identify the most effective architectural approach under various real-world conditions.
\end{enumerate}

These objectives guide the development and validation of a system that is not only technically sound but also practical and scalable in industrial settings.


\section{Thesis Outline}

Following this introduction, the thesis begins with a discussion of related work in the field. This includes an overview of existing systems for template filling, particularly those that use speech input or large language models. The literature is analyzed to identify current limitations and to derive a clear set of requirements for building a better, more modular solution.

Next, the conceptual foundation of the proposed system is introduced. The structure of Invox is explained, along with four different design strategies that use large language models in distinct ways. These approaches are described in detail, along with the reasoning behind each one and a discussion of possible alternatives.

After outlining the concept, the implementation is described. This includes the software architecture, technology choices, and how each component—such as speech transcription, RAG, field extraction, and answer verification—was built. Attention is given to how modularity was achieved to support maintainability and reuse.

The following part of the thesis presents the working prototype. Screenshots, mockups, and usage examples are used to demonstrate how the system operates in practice. The user interface and interactions are shown, illustrating how speech input can be turned into a structured form with minimal effort.

Once the system is introduced and demonstrated, the evaluation section presents a detailed analysis of its performance. A benchmark dataset is used to test the system across four architectural approaches. The results are analyzed using metrics such as accuracy, latency, consistency, and computational cost.

The final part of the thesis summarizes the key findings, reflects on the strengths and limitations of the current implementation, and proposes ideas for future research and system improvements.
