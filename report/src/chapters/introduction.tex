During a night shift at a manufacturing plant, an operator notices unusual vibrations in a critical machine and must document equipment performance and anomalies for the incoming team. In a busy emergency room, a doctor treating a patient with chest pain must record symptoms, vitals, medical history, and treatments in a standardized intake form. Although from different domains, both tasks rely on structured information capture to ensure continuity, safety, and compliance.

Across industries—including healthcare, manufacturing, logistics, and customer service—workers routinely populate templates such as forms, logs, and reports. This general task, known as \textit{template filling}, requires mapping unstructured observations into predefined fields. It is essential for documentation quality but also time-consuming and error-prone, especially when workers are fatigued. Manual entries often vary in detail, omit required fields, or contain stylistic inconsistencies that impede downstream analysis.

Template filling appears in many settings, from clinical intake forms~\cite{du2021template} and industrial maintenance logs~\cite{wang2021spoken} to web automation~\cite{chen2024webform} and customer service platforms~\cite{sun2023slot}. The main challenge is not collecting information but reliably converting unstructured text—or speech—into structured formats. This cognitive effort can be significant, especially after demanding shifts where important details may be forgotten or recorded inconsistently.

AI assistants and modern NLP technologies offer an alternative: users can describe events freely, and AI systems convert these descriptions into structured template fields. This reduces cognitive load, improves consistency, and allows the system to detect missing or contradictory information. In hands-busy environments—such as technicians wearing protective gear or clinicians examining patients—speech-based filling is especially promising~\cite{wang2021spoken}.

This shift is driven by advances in \textit{automatic speech recognition (ASR)} and \textit{large language models (LLMs)}. ASR systems like Whisper now transcribe speech accurately across accents, noise levels, and informal phrasing~\cite{radford2023whisper, fathullah2023prompting}. Meanwhile, LLMs such as GPT-4 and Claude can interpret context, extract structured information, and resolve ambiguities in user descriptions~\cite{du2021template, mialon2023augmented}.

Most current ASR+LLM systems rely on a \textit{monolithic} design in which a single model performs understanding and template filling~\cite{sun2022023slot, chen2024webform}. Such systems offer simplicity but lack transparency and are difficult to adapt: errors cannot be traced to specific steps, and new forms often require retraining the entire model~\cite{liu2022conversational}. Spoken input further complicates the pipeline—speech is frequently disfluent, unordered, or incomplete~\cite{fathullah2023prompting}.

To overcome these limitations, recent work advocates \textit{modular or multi-agent architectures}, where transcription, field identification, value extraction, and validation are handled by separate components~\cite{mialon2023augmented, schick2023toolformer}. This improves interpretability, maintainability, and adaptability to new domains. Building on this line of research, this thesis presents \textbf{Invox}, a modular system for speech-based template filling tailored to realistic industrial conditions.

\section{Problem Description}

While recent advances in large language models (LLMs) have made it easier to build systems for filling out forms automatically, most existing solutions rely on a \textit{monolithic design}, where a single model handles the entire task of understanding input and generating all required field values in one step. For instance, Du et al.~\cite{du2021template} propose zero-shot prompting to generate complete templates from unstructured text, while Chen et al.~\cite{chen2024webform} apply large language models to populate web-based forms via single-shot prompts. Similarly, Sun et al.~\cite{sun2023slot} introduce a slot-filling pipeline that decodes all fields in a unified pass. Although effective in controlled settings, such monolithic approaches become brittle when processing real-world input, which is often unstructured, incomplete, ambiguous, or contains irrelevant information—making these systems hard to adapt, debug, or extend across domains. Whether the input comes from free-form text descriptions, conversational dialogue, or speech transcriptions, the fundamental challenge remains: mapping loosely structured human communication into rigid template formats while handling the inherent messiness of natural language.

One major issue is \textit{fragility}. These models are often trained on specific types of inputs or formats, and they may fail when the input varies slightly—such as when someone uses uncommon phrasing, mixes up the order of fields, or leaves out certain information~\cite{fathullah2023prompting, liu2022conversational}. This is common in real-world situations, where people speak naturally and often provide extra details, use abbreviations, or skip fields they assume are obvious. When a monolithic model encounters this variation, it might leave fields blank, insert wrong values, or produce inconsistent results~\cite{wang2021spoken, sun2023slot}.

Another major challenge is \textit{lack of transparency}. When a single model does the entire job, it is difficult to figure out what went wrong if the result is incorrect. For example, was the problem caused by a transcription error, misunderstanding of the content, or a failure in mapping the answer to the correct field? Because all steps are handled together, it is hard to trace and fix errors, which limits the system’s reliability and maintainability~\cite{schick2023toolformer}.

Additionally, current systems are \textit{hard to customize} for different industries or forms. Each form may have its own structure, required fields, and domain-specific language. Changing the model to handle a new type of report or form often means retraining or redesigning the entire system~\cite{du2021template, mialon2023augmented}. This makes it expensive and time-consuming to adapt these systems to new domains.

These problems are even more pronounced because current approaches present isolated AI models rather than complete, flexible systems. While individual models may excel at specific subtasks—such as information extraction, field classification, or consistency validation—there is no readily-usable end-to-end system that integrates these capabilities in a cohesive and adaptable manner. In practice, building robust template filling solutions requires combining multiple specialized models and components to create an improved process that can handle real-world variability, domain-specific requirements, and evolving template structures. As a result, current one-step systems often fail in practical deployment scenarios where templates vary across departments, input quality is inconsistent, or the system needs to adapt to new fields and formats over time without requiring complete retraining.

To solve these problems, there is a need for a more flexible, transparent, and modular approach that separates the process into smaller, understandable steps. This allows better error handling, easier debugging, and faster adaptation to new use cases~\cite{mialon2023augmented, schick2023toolformer}.

\section{Motivating Scenario}

To illustrate the challenges of template filling in real-world environments, consider a typical shift in the \textit{steel manufacturing industry}.

Steel plant operators work under intense conditions—loud machinery, high heat, and strict production deadlines. At the end of each 8-hour shift, they are expected to submit a \textit{shift report} documenting safety incidents, equipment issues, production figures, and handover notes. These reports are essential for maintaining operational continuity, safety compliance, and accountability. Yet in practice, workers often fill them out hastily—sometimes incompletely or not at all—especially during late-night shifts or when fatigued.

To reduce the burden of manual form filling, workers and organizations have begun exploring various assistive technologies and workarounds. While many organizations have transitioned to digitalized forms accessible via tablets or computers, the fundamental challenge of structuring information remains unchanged—workers still must manually map their observations into predefined fields. Some organizations have experimented with dictation tools or voice recording as intermediate steps, where workers provide free-form descriptions that supervisors later process into structured reports. However, such approaches merely shift the burden rather than solving it: someone must still perform the cognitive work of listening to unstructured accounts and extracting relevant information for each template field. This highlights a critical need for intelligent systems that can assist in the transformation from unstructured human communication to structured data, regardless of the input modality.

Now imagine an intelligent system that could take these raw audio notes, transcribe them, interpret their meaning, and fill in the shift report automatically. For instance, if a worker says:

\begin{quote}
``We had a minor safety incident near the blast furnace around 2 p.m.—someone tripped, but no injuries. Conveyor belt on Line B stopped twice, restarted after 10 minutes each time. Production target met—482 tons.''
\end{quote}

Such a system would ideally extract structured information like:
\begin{itemize}
    \item \textbf{Safety Incident:} Minor, near blast furnace, no injuries
    \item \textbf{Time:} Around 2 p.m.
    \item \textbf{Equipment Issue:} Line B conveyor belt stopped twice
    \item \textbf{Production:} 482 tons
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.35]{images/Motivation.png}
    \caption{Invox: From spoken input to structured report}
    \label{fig:invox-motivation}
\end{figure}

Although this task may seem straightforward, it is far from trivial. Spoken input is often informal, unordered, and filled with vague expressions or filler words. Terms like “blast furnace” or “Line B” reflect domain-specific knowledge that the system must understand. Noise, fatigue, and rushed speech introduce further variability.

This scenario reveals four core challenges in automating template filling:
\begin{itemize}
\item \textbf{Unstructured input:} Workers communicate naturally through free-form descriptions rather than following predefined template structures, requiring systems to interpret and map loosely organized information into rigid formats.
\item \textbf{Inconsistency and incompleteness:} Human-generated descriptions vary widely in detail, writing style, and vocabulary, often omitting critical information or including irrelevant details that must be filtered out.
\item \textbf{Domain-specific language:} Specialized terminology, abbreviations, and jargon must be correctly recognized and interpreted within their contextual meaning, which varies across industries and departments.
\item \textbf{Lack of integrated systems:} Current solutions rely on isolated AI models rather than flexible, end-to-end systems that can adapt to different template formats, handle multiple input modalities, and evolve with changing organizational needs.
\end{itemize}

Together, these challenges underscore the need for a more intelligent and adaptable approach. A modular system like \textbf{Invox}, capable of processing speech, identifying relevant fields, and generating structured output, offers a scalable solution tailored to the complexities of real industrial environments.


\section{Scope of the Thesis}
This thesis focuses on practical form-filling methods that convert noisy, unstructured spoken input into structured digital records, introducing realistic benchmark datasets and, to the best of our knowledge, the first end-to-end system based on large-scale pretrained models that can be efficiently used in real-world applications.

The primary use case addressed is shift documentation in the steel manufacturing industry. Operators in this domain often record verbal summaries at the end of their shifts, describing production events, safety incidents, and equipment issues. These recordings are typically informal, multilingual, and captured in noisy environments. This makes the use case ideal for evaluating robustness in low-structure, real-world input scenarios~\cite{wang2021spoken, fathullah2023prompting}.

The technical scope of this work includes the use of state-of-the-art automatic speech recognition (ASR) models—specifically OpenAI's Whisper~\cite{radford2023whisper}—combined with large language models (LLMs) such as GPT-5, Gemini-2.5-pro, etc. These components are orchestrated in a modular agent-based architecture for handling tasks like transcription interpretation, field-value mapping, and validation. No fine-tuning or training of models is performed; the focus is on system-level orchestration and domain-adapted prompt engineering.

The evaluation is limited to the accuracy and reliability of the structured output produced from recorded input. This thesis does not cover areas such as UI/UX design, live streaming input, conversational turn-taking, or the deployment of on-device inference. Instead, it aims to explore how existing ASR and LLM technologies can be effectively combined into a practical and scalable speech-based form filling system suitable for high-noise industrial domains.


\section{Objectives}

The main objective of this thesis is to design and evaluate a modular system—called \textbf{Invox}—that can automatically fill out structured forms using unstructured speech or text input. The system aims to overcome the limitations of current single-model, end-to-end solutions by introducing a flexible, multi-agent approach that separates the task into smaller, specialized components.

To achieve this goal, the following two specific objectives are defined:

\begin{enumerate}
    \item \textbf{Design a modular multi-agent architecture} for template filling that separates the process into subtasks such as transcription, field detection, answer generation, and verification—each handled by a dedicated agent. This design supports flexibility, transparency, and domain adaptability. As part of this design, five distinct prompting strategies are implemented using large language models (LLMs), ranging from single-pass full-input methods to iterative multi-model consensus approaches. These strategies are chosen to reflect different trade-offs in accuracy, latency, cost, and interpretability.

    \item \textbf{Evaluate the system performance} using a hybrid strategy that combines standardized benchmarking and real-world testing. For benchmarking, the official MUC-4 evaluation protocol \cite{chinchor1992muc4} is applied, using slot-level precision, recall, and F1-score to compare structured information extraction. Finally, results from all prompting strategies are compared to identify the most effective architectural approach under various real-world conditions.
\end{enumerate}

These objectives guide the development and validation of a system that is not only technically sound but also practical and scalable in industrial settings.


\section{Thesis Outline}

Following this introduction, the thesis begins with a discussion of related work in the field. This includes an overview of existing systems for template filling, particularly those that use speech input or large language models. The literature is analyzed to identify current limitations and to derive a clear set of requirements for building a better, more modular solution.

Next, the conceptual foundation of the proposed system is introduced. The structure of Invox is explained, along with four different design strategies that use large language models in distinct ways. These approaches are described in detail, along with the reasoning behind each one and a discussion of possible alternatives.

After outlining the concept, the implementation is described. This includes the software architecture, technology choices, and how each component—such as speech transcription, RAG, field extraction, and answer verification—was built. Attention is given to how modularity was achieved to support maintainability and reuse.

The following part of the thesis presents the working prototype. Screenshots, mockups, and usage examples are used to demonstrate how the system operates in practice. The user interface and interactions are shown, illustrating how speech input can be turned into a structured form with minimal effort.

Once the system is introduced and demonstrated, the evaluation section presents a detailed analysis of its performance. A benchmark dataset is used to test the system across four architectural approaches. The results are analyzed using metrics such as accuracy, latency, consistency, and computational cost.

The final part of the thesis summarizes the key findings, reflects on the strengths and limitations of the current implementation, and proposes ideas for future research and system improvements.
