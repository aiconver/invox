This chapter presents the conceptual foundation of the proposed solution, grounded in the requirements and limitations identified in Chapter 2. The core objective is to transform unstructured narrative input—whether spoken or typed—into structured, schema-conformant templates through a modular, agent-based architecture. Unlike monolithic approaches that attempt end-to-end extraction in a single inference step, the proposed system decomposes the task into specialized subtasks, each handled by a dedicated agent with clearly defined responsibilities and interfaces.

The design is motivated by three critical shortcomings observed in existing work. First, single-model systems lack transparency: when extraction fails, it is difficult to trace whether the error originated in entity recognition, field mapping, or format normalization \cite{du2021template, sun2023slot}. Second, monolithic architectures are brittle under noisy or domain-specific input, as they cannot isolate and recover from localized failures \cite{wang2021spoken}. Third, current solutions provide limited support for iterative refinement, user correction, or learning from domain knowledge, restricting their adaptability in real-world deployments \cite{mialon2023augmented, park2023generative}.

The proposed Invox system addresses these limitations through a five-stage pipeline that enforces separation of concerns while preserving end-to-end coherence. Each agent operates on well-defined inputs and produces structured outputs that serve as inputs to downstream components. This modular design directly supports the six requirements established in Section 2.1: consistency is enforced through dedicated normalization (R1), extraction accuracy benefits from retrieval-augmented context (R2), intermediate artifacts enable traceability (R3), outputs remain editable at the end before final submission (R4), the system learns from historical templates and domain resources (R5), and architectural strategies can be selected to meet latency constraints (R6).

The remainder of this chapter is organized as follows. Section 3.1 derives the conceptual design from the analysis results, explaining how each requirement motivates specific architectural decisions. Section 3.2 describes the five modular agents that comprise the pipeline, detailing their individual responsibilities, inputs, outputs, and internal mechanisms. Section 3.3 presents four architectural strategies—Single-Pass Full Input, Iterative Single-Field Processing, Multi-LLM Consensus (Full), and Multi-LLM Consensus (Iterative)—that instantiate the same pipeline with different trade-offs in accuracy, latency, and cost. Section 3.4 provides the high-level system architecture and design, including context diagrams, container views, and process flows that illustrate how components interact in deployment scenarios. Detailed implementation and experimental validation are deferred to Chapters 4 and 5, respectively.

\input{src/chapters/concept/concept_derivations}
\input{src/chapters/concept/agents}
\input{src/chapters/concept/strategies}
\input{src/chapters/concept/system_architecture_and_design}