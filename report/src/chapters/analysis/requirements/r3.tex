Transparency refers to the framework’s ability to make its decision-making process visible to users by exposing both the evidence behind each extracted value and the system’s level of certainty in that value. Unlike black-box systems that present outputs without explanation, a transparent framework not only shows the populated fields but also reveals the reasoning path by which they were derived. This includes identifying the input fragments that served as evidence and providing explicit indicators of how confident the system is in its interpretations~\cite{doshi2017towards, samek2019explainable}.  

As illustrated in Figure~\ref{fig:form-filling-example}, transparency in an ideal framework means that populated values are never shown in isolation but are accompanied by their supporting evidence and a confidence indicator. The figure highlights how a field such as a date is linked back to the exact phrase in the transcript and annotated with a certainty level, making the reasoning process visible rather than opaque.

This requirement matters because users often interact with template filling systems in high-stakes environments where correctness cannot be taken for granted. In domains such as healthcare, industrial inspection, or compliance reporting, an incorrectly extracted date, measurement, or symptom could lead to operational errors or legal consequences. Without transparency, users are left to either blindly trust the system or manually re-check all outputs. Both outcomes undermine efficiency and adoption. By contrast, when the system highlights the origin of each extracted field and communicates its confidence level, users can selectively verify uncertain or ambiguous entries, thereby improving both trust and productivity~\cite{wang2022trust, ribeiro2016should}.  

In practice, transparency is achieved through two complementary mechanisms. First, source highlighting makes explicit which text fragments in the input led to the population of a given field. For instance, if the transcript contains the phrase “scheduled for 08/16/2025,” the system should highlight this fragment as the evidence for the “Date” field. This allows users to directly trace values back to their textual origins and verify their correctness. Second, confidence scores quantify the system’s certainty about each extracted value. These can be expressed as probabilities (e.g., 0.82 confidence in the extracted date) or as categorical levels (e.g., high, medium, low). Confidence scores help users prioritize where to invest their attention, focusing on entries that are most likely to contain errors while trusting those that are more secure. Together, these mechanisms turn opaque predictions into traceable, verifiable decisions.  

The advantages of transparency are multifold. It builds user trust by establishing a clear link between input data and structured outputs, reducing the perception of the system as a “black box.” It enables efficient error detection, since users can quickly locate uncertain or weakly supported values without re-checking the entire template. Transparency also facilitates training and feedback, as developers and domain experts can identify systematic error patterns by examining low-confidence predictions and their sources~\cite{thomas2019interacting}. Finally, transparency supports compliance in regulated industries by providing auditable evidence trails that show not only what the system decided but also why it decided it.  

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.6}
\setlength{\tabcolsep}{12pt}
\begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}m{3cm}|>{\arraybackslash}X|}
\hline
\textbf{Visual Score} & \textbf{Interpretation} \\
\hline
\centering\raisebox{0pt}{\tikz[baseline]{\filldraw[fill=black] (0,0) circle (0.4cm);}} 
& \textbf{Both criteria satisfied.} The system highlights the exact text fragments that led to each populated field and provides confidence scores for all extracted values. \\
\hline
\centering\raisebox{0pt}{\tikz[baseline]{\filldraw[fill=black] (0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} 
& One criterion satisfied (e.g., confidence scores are displayed but no source highlighting is provided, or vice versa). \\
\hline
\centering\raisebox{0pt}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} 
& No criteria satisfied. The system provides populated fields without indicating their source or the certainty of extraction, leaving the process opaque. \\
\hline
\end{tabularx}
\caption{Evaluation Scale for R3: Transparency}
\label{tab:r3-transparency}
\end{table}

To summarize, transparency ensures that extracted template values are not only presented as results but also explained in terms of their origins and associated confidence levels. By exposing the reasoning process, the system strengthens user trust, enables efficient verification, and provides the auditability necessary for both iterative improvement and compliance in regulated domains.
