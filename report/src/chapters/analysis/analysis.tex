This chapter identifies the fundamental requirements for converting natural language into structured templates and critically examines existing approaches. The goal is to establish a systematic basis for evaluating current methods and to derive implications for the design of the proposed framework.

\section{Requirements}
\label{sec:requirements}

This section outlines the core requirements that a system must fulfill to transform natural language input into structured templates with predefined fields. Such templates are widely used across domains, including healthcare (e.g., patient checklists), manufacturing (e.g., quality inspections), and logistics (e.g., delivery reports).

The primary goal of the system presented in this thesis, named Invox, is to support users in filling out these templates more easily, quickly, and accurately. Instead of using traditional tools like a mouse, keyboard, or touchscreen, users interact with the system using natural language. This input can be typed or spoken aloud—both are valid forms of unstructured data. However, it is important to note that voice-based input is just one way of using the system; the true innovation lies in how the system processes and understands natural human language and translates it into structured form data.

In the introduction, we defined six core requirements (R1–R6) for a practical, LLM-based form-filling system. These requirements capture the desired capabilities (e.g., handling unstructured input, correctly populating forms) as well as non-functional aspects such as robustness, efficiency, and applicability in realistic scenarios.

In this chapter, we analyse the proposed multi-agent architecture with respect to these requirements. For each requirement R1–R6, we outline how it is evaluated, and to what extent the system satisfies it in practice.

However, building such a system is not straightforward. Several challenges must be addressed to ensure the solution is usable, reliable, and trustworthy across real-world scenarios. To clearly define what such a system should achieve, we identify the following six requirements:   

\textbf{R1 – Consistency:}  
The system must be able to transform heterogeneous and informal input—such as voice transcriptions, chat messages, or handwritten notes—into consistently populated template fields. It should normalize wording, tonality, length, and semantic specificity, and enforce formatting standards so that entries are comparable, unambiguous, and suitable for downstream analysis.  

\textbf{R2 – Information Extraction Abilities:}  
The system should accurately identify and assign relevant details from noisy, fragmented, or multilingual input to the correct fields, while leaving irrelevant fields empty. It must recognize when required information is missing, handle contradictions by prompting for clarification, and integrate scattered fragments into coherent entries.  

\textbf{R3 – Transparency:}  
To foster trust and accountability, the system must make its decision-making process visible. It should highlight the input fragments that support each extracted value and provide confidence scores to indicate the certainty of those values. This enables users to verify outputs efficiently, focus on uncertain cases, and ensure auditability in regulated domains.  

\textbf{R4 – User Correction:}  
The system must enable users to manually edit automatically populated template fields. This ensures immediate error resolution without requiring retraining and empowers users with direct control over the accuracy of the final data submitted.  

\textbf{R5 – Learning and Adaptation:}  
The system should improve over time by consolidating knowledge from past interactions and domain resources. It must learn from manually filled or corrected templates as well as from structured sources such as ontologies, glossaries, or rule sets, progressively reducing repetitive errors and improving alignment with domain-specific practices.

\textbf{R6 – Usability:}  
The system must deliver prompt, near–real-time feedback so interaction feels natural and uninterrupted. This requirement applies to both spoken and typed input (speech is only one use case). Usability is evaluated via end-to-end latency and must be interpreted relative to the declared hardware and deployment profile (e.g., GPU/TPU vs.\ CPU-only, concurrency, network).

These six requirements were identified based on the challenges discussed in Chapter 1 and are aligned with recent work on natural language processing, conversational interfaces, and intelligent form-filling systems. Each of the following sections will examine one requirement in detail. We explain what the requirement means, why it matters, and illustrate it with examples. For each requirement, we also define assessment standards that help evaluate how well the system satisfies the requirement in practice.  

To make these requirements more concrete, Figure~\ref{fig:form-filling-example} shows a practical usage scenario of the Invox framework. On the left, the user provides a natural language description, which the assistant processes into a structured template on the right. Some fields are automatically filled with extracted values, while others remain highlighted as incomplete and require user clarification. This illustration highlights the central challenges addressed by the requirements: ensuring consistent representation of entries (R1), accurately extracting relevant details (R2), providing transparency about what was filled and why (R3), enabling user correction of missing or incorrect fields (R4), creating a foundation for gradual learning and adaptation over time (R5), and maintaining responsiveness so updates appear promptly during interaction (R6).

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/form-filling-example.png}
    \caption{Example interaction with the proposed AI voice form assistant.}
    \label{fig:form-filling-example}
\end{figure}

On the left, the user provides an unstructured spoken description of a conveyor belt malfunction, which is transcribed in the chat interface. On the right, the system has automatically populated the corresponding incident report form with structured fields such as the reporting person, issue title, problem description, and corrective action. Fields that cannot be reliably inferred from the input (e.g., \emph{Date of Report} and \emph{Affected Machine or Production Line}) are left empty, highlighted, and explicitly requested from the user. This illustrates how the framework maps free-form input onto a structured template while interactively resolving missing information.

\subsection{R1: Consistency}\vspace{-2mm}
\input{src/chapters/analysis/requirements/r1} 

\subsection{R2: Information Extraction}\vspace{-2mm}
\input{src/chapters/analysis/requirements/r2} 

\subsection{R3: Transparency}\vspace{-2mm}
\input{src/chapters/analysis/requirements/r3} 

\subsection{R4: User Correction}\vspace{-2mm}
\input{src/chapters/analysis/requirements/r4}

\subsection{R5: Learning and Adaptation}\vspace{-2mm}
\input{src/chapters/analysis/requirements/r5}

\subsection{R6: Usability}\vspace{-2mm}
\input{src/chapters/analysis/requirements/r6}


\section{Related Work}
\label{sec:related-work}

The transformation of unstructured language into structured templates is a core challenge in natural language processing, spanning information extraction, semantic parsing, and template filling. Classical rule-based and statistical methods often fail to handle the ambiguity and variability of free-form text \cite{doddington2004ace}. With the rise of large language models (LLMs), this task has gained renewed attention, as modern models offer strong contextual understanding and improved structured output generation \cite{bastianelli2020slurp}. Recent work further shows that LLMs can generalize across domains and input modalities, supporting more robust end-to-end systems for transforming unstructured text or speech into structured representations.

However, despite these advances, current approaches often struggle with the specific requirements identified in Section 2.1, particularly when dealing with noisy, domain-specific, or incomplete inputs common in real-world industrial and professional settings. This section examines the current state of research relevant to multi-agent template filling systems, with particular focus on how existing approaches address the core challenges of consistency, information extraction accuracy, transparency, user correction capabilities, learning mechanisms, and usability. The analysis reveals significant gaps in current methodologies, particularly in their monolithic design assumptions and limited adaptability to specialized domains.

The review is organized into three key areas that directly inform the design of the proposed Invox system.\\[1pt]
\hspace*{1.5em}\textbf{i)} \textbf{Template filling and structured information extraction:} we examine traditional and modern approaches, tracing the evolution from rule-based pipelines to contemporary LLM-driven methods.\\[1pt]
\hspace*{1.5em}\textbf{ii)} \textbf{Prompt engineering techniques:} we analyze strategies that guide LLMs toward reliable structured output generation and improved controllability.\\[1pt]
\hspace*{1.5em}\textbf{iii)} \textbf{Multi-agent LLM systems:} we explore architectures that decompose complex tasks into specialized components, addressing modularity, transparency, and the limitations of monolithic approaches.

\subsection{Template Filling and Structured Information Extraction}
\input{src/chapters/analysis/related_works/w1}

\subsection{Prompt Engineering for Information Extraction}
\input{src/chapters/analysis/related_works/w2}

\subsection{Multi-Agent LLM Systems}
\input{src/chapters/analysis/related_works/w3}

\subsection{Overall Evaluation and Gaps}
\input{src/chapters/analysis/related_works/w4}
