While single-model prompting can achieve strong results, it often struggles with reliability, transparency, and adaptability in complex tasks. Recent work has therefore explored \emph{multi-agent systems}, where large language models are organized as a cooperating group of agents with different roles. Instead of relying on a single LLM to handle extraction, validation, reasoning, and correction, tasks can be decomposed into smaller subtasks performed by specialized agents.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{images/single_vs_multi_model.png}
    \caption{Comparison of single-model and multi-agent approaches.}
    \label{fig:single-vs-multi}
\end{figure}

One of the most prominent examples is \textbf{HuggingGPT}, introduced by Shen et al.\ \cite{shen2023hugginggpt}. In this system, an LLM serves as a controller that interprets user requests, decomposes them into subtasks, and delegates them to external models on the Hugging Face platform. The controller then integrates the results into a final output. Liang et al.\ \cite{liang2023taskmatrix} proposed a similar architecture with \textbf{TaskMatrix.AI}, which connects LLMs to thousands of APIs, enabling each subtask to be handled by the tool best suited for it. These studies conceptualize LLMs not as monolithic solvers but as managers capable of coordinating heterogeneous toolchains.

Multi-agent ideas have also been applied directly to document understanding and extraction. Park et al.\ \cite{park2023generative} propose cooperative generative agents in which one agent extracts candidate entities while another validates or reformats them to fit schema constraints. This separation of responsibilities reduces cognitive load for each model and provides clearer debugging signals, since errors can be traced to a specific agent. Du et al.\ \cite{du2023improving} study multi-agent dialogue in which agents assume distinct roles (e.g., information seeker, verifier, summarizer) to improve factual consistency. Such role-based decomposition can be transferred to template filling: one agent extracts fields, a second checks completeness, and a third revises or corrects outputs.

Consensus-based multi-agent systems add another reliability mechanism. Wu et al.\ \cite{wu2023autoagents} introduce \textbf{AutoAgents}, an open-source framework where multiple agents generate alternative solutions that are then aggregated or voted on. This ensemble-style approach reduces variance and improves robustness, functioning similarly to redundancy and majority-voting techniques in classical ensemble learning but enhanced by the contextual reasoning abilities of LLMs. Consensus methods are particularly useful for noisy or ambiguous inputs, where a single-model output might fluctuate.

Despite these advantages, multi-agent systems also introduce challenges. Coordination overhead increases computational cost and latency, and poorly designed agent interfaces can create cascading errors. Evaluation of cooperation quality remains limitedâ€”most benchmarks measure final outputs but not the reliability of inter-agent communication. Multi-agent systems therefore offer greater transparency and robustness, but at the cost of complexity and resource usage.

\subsubsection{Evaluation Against Requirements}

Table~\ref{tab:eval-multi-agent} evaluates the reviewed multi-agent approaches against requirements R1--R6 using the scoring scales defined in Section~2.1.

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.5}
\setlength{\tabcolsep}{10pt}
\small
\begin{tabular}{|m{5cm}|c|c|c|c|c|c|}
\hline
\textbf{Approach / System} & \textbf{R1} & \textbf{R2} & \textbf{R3} & \textbf{R4} & \textbf{R5} & \textbf{R6} \\
\hline

HuggingGPT (Shen et al.) &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
--- \\
\hline

TaskMatrix.AI (Liang et al.) &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
--- \\
\hline

Cooperative extraction (Park et al.) &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
--- \\
\hline

Consensus systems (AutoAgents, Wu et al.) &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) circle (0.4cm);}} &
--- \\
\hline

\end{tabular}
\caption{Evaluation of multi-agent approaches against requirements R1--R6.}
\label{tab:eval-multi-agent}
\end{table}

\subsubsection{Summary}

Multi-agent systems provide several advantages over single-model prompting, particularly in complex extraction settings. They demonstrate strong performance in \textbf{information extraction} (R2) and show clear strengths in \textbf{transparency} (R3) and \textbf{adaptability} (R5), since responsibilities are divided across specialized agents and intermediate decisions become inspectable. Consensus-based systems achieve particularly high consistency and robustness (R1) by aggregating multiple agent outputs.

However, multi-agent architectures still lack integrated \textbf{user correction} mechanisms (R4), and none report concrete \textbf{usability} or latency metrics (R6). Furthermore, their increased coordination overhead makes them computationally heavier and more complex to deploy.

Overall, multi-agent methods offer promising benefits for reliability, interpretability, and modularity, but also introduce trade-offs in cost, latency, and pipeline complexity. These trade-offs motivate the comparative evaluation in this thesis, where multi-agent strategies are assessed alongside monolithic and hybrid approaches.
