While single-model prompting can achieve strong results, it often struggles with reliability, transparency, and adaptability in complex tasks. Recent work has therefore explored \emph{multi-agent systems}, where large language models are organized as a cooperating group of agents with different roles. Instead of relying on a single LLM to handle extraction, validation, reasoning, and correction, tasks can be decomposed into smaller subtasks performed by specialized agents.

One of the most prominent examples is \textbf{HuggingGPT}, introduced by Shen et al.\ \cite{shen2023hugginggpt}. In this system, an LLM serves as a controller that interprets user requests, decomposes them into subtasks, and delegates them to external models on the Hugging Face platform. The controller then integrates the results into a final output. Liang et al.\ \cite{liang2023taskmatrix} proposed a similar architecture with \textbf{TaskMatrix.AI}, which connects LLMs to thousands of APIs, enabling each subtask to be handled by the tool best suited for it. These studies conceptualize LLMs not as monolithic solvers but as managers capable of coordinating heterogeneous toolchains.

Multi-agent ideas have also been applied directly to structured reasoning and information extraction. Qian et al.~\cite{qian2023communicative} demonstrate that assigning agents complementary roles—such as extractor, verifier, and corrector—improves factual consistency and reduces hallucinations through inter-agent critique. This structured division of labour aligns well with template-filling workflows, where one agent extracts fields, another checks completeness, and a third corrects schema violations. Ye et al.~\cite{ye2025guided} further show that guided and knowledge-grounded multi-agent debate improves factual verification by coordinating specialised agents with different reasoning strategies, illustrating how debate-driven refinement can enhance reliability in complex extraction pipelines.

Consensus-based multi-agent systems add another reliability mechanism. Wu et al.\ \cite{wu2023autoagents} introduce \textbf{AutoAgents}, an open-source framework where multiple agents generate alternative solutions that are then aggregated or voted on. This ensemble-style approach reduces variance and improves robustness, functioning similarly to redundancy and majority-voting techniques in classical ensemble learning but enhanced by the contextual reasoning abilities of LLMs. Consensus methods are particularly useful for noisy or ambiguous inputs, where a single-model output might fluctuate.

Despite these advantages, multi-agent systems also introduce challenges. Coordination overhead increases computational cost and latency, and poorly designed agent interfaces can create cascading errors. Evaluation of cooperation quality remains limited—most benchmarks measure final outputs but not the reliability of inter-agent communication. Multi-agent systems therefore offer greater transparency and robustness, but at the cost of complexity and resource usage.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{images/single_vs_multi_model.png}
    \caption{Comparison of single-model and multi-agent approaches. Single-model systems are simple and efficient but offer little transparency, while multi-agent systems increase cost and complexity in exchange for greater modularity and interpretability.}
    \label{fig:single-vs-multi}
\end{figure}

\subsubsection{Evaluation Against Requirements}

Table~\ref{tab:eval-multi-agent} evaluates the discussed multi-agent approaches against requirements R1--R6 using the scoring scales defined in Section~2.1.
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.5}
\setlength{\tabcolsep}{10pt}
\small
\begin{tabular}{|m{5cm}|c|c|c|c|c|c|}
\hline
\textbf{Approach / System} & \textbf{R1} & \textbf{R2} & \textbf{R3} & \textbf{R4} & \textbf{R5} & \textbf{R6} \\
\hline

HuggingGPT~\cite{shen2023hugginggpt} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black] (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
--- \\
\hline

TaskMatrix.AI~\cite{liang2023taskmatrix} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black] (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
--- \\
\hline

Cooperative extraction~\cite{wang2025cooperative} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-150:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
--- \\
\hline

Consensus systems ~\cite{chen2023autoagents} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black] (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black] (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black]
(0,0) -- (90:0.4cm) arc (90:-90:0.4cm) -- cycle; \draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\draw (0,0) circle (0.4cm);}} &
\raisebox{-0.1cm}{\tikz[baseline]{\filldraw[fill=black] (0,0) circle (0.4cm);}} &
--- \\
\hline

\end{tabular}
\caption{Evaluation of multi-agent approaches against requirements R1--R6.}
\label{tab:eval-multi-agent}
\end{table}

The evaluation reveals that multi-agent approaches offer clear strengths in \textbf{information extraction} (R2), \textbf{transparency} (R3), and \textbf{adaptability} (R5). By distributing responsibilities across specialised agents, intermediate decisions become inspectable, and the system can combine diverse capabilities such as retrieval, validation, and consensus building. Consensus-based systems in particular achieve strong \textbf{consistency} (R1) through aggregation across multiple agent outputs.

At the same time, all reviewed systems lack integrated \textbf{user correction} mechanisms (R4) and do not report \textbf{usability} or latency characteristics (R6), making their real-world responsiveness unclear. Multi-agent designs also introduce coordination overhead, increasing computational cost and deployment complexity.

Overall, the table highlights a key trade-off: multi-agent architectures significantly improve reliability, interpretability, and modularity but at the expense of higher cost and complexity. This trade-off directly motivates the architectural decisions in this thesis, where multi-agent strategies are evaluated alongside monolithic and hybrid approaches.
